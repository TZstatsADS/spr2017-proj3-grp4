fulltext<-Corpus(DirSource(folder.path))
fulltext<-tm_map(fulltext, stripWhitespace)
fulltext<-tm_map(fulltext, content_transformer(tolower))
fulltext<-tm_map(fulltext, removeWords, stopwords("english"))
fulltext<-tm_map(fulltext, removeWords, character(0))
fulltext<-tm_map(fulltext, removePunctuation)
fulltext<-tm_map(fulltext, stemDocument)
text<-tm_map(fulltext, stripWhitespace)
fulltext<-tm_map(fulltext, removePunctuation)
fulltext<-tm_map(fulltext, removeNumbers)
fulltext<-tm_map(fulltext, PlainTextDocument)
dtm <- DocumentTermMatrix(fulltext)
dtms <- removeSparseTerms(dtm, 0.1)
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
wf <- data.frame(word=names(freq), freq=freq)
ggplot(subset(wf, freq>300), aes(word, freq))+
geom_bar(stat="identity")+
theme(axis.text.x=element_text(angle=45, hjust=1),plot.title = element_text(size = 20, face = "bold",hjust = 0.5))+
labs(list(title = "Words Frequency (more than 300 times) ", x = "Year", y = "words amount"))
nrow(subset(wf, freq>300))
wf[which.max(wf$freq),]
#people vs govern
for (i in 1:nrow(speech.list))
{
speech.list$people[i]=length(gregexpr("people",speech.list$fulltext[i])[[1]])/speech.list$Words[i]*100
speech.list$govern[i]=length(gregexpr("govern",speech.list$fulltext[i])[[1]])/speech.list$Words[i]*100
}
sublist=speech.list[,c("year","people","govern")]
sub=melt(sublist,id="year")
ggplot(data=sub)+
geom_point(aes(x=year, y=value, colour=variable))+
geom_smooth(aes(x=year, y=value, colour=variable),se=F,method="lm")+
labs(list(title = "Words Frequncy (every 100 words)", x = "Year", y = "words"))+
theme(plot.title = element_text(size = 20, face = "bold",hjust = 0.5))
for (i in 1:nrow(speech.list))
{
speech.list$great[i]=length(gregexpr("great",speech.list$fulltext[i])[[1]])/speech.list$Words[i]*100
}
ggplot(data=speech.list,aes(x=year,y=great))+
geom_bar(stat="identity")+
labs(list(title = "Words Frequncy (every 100 words)", x = "Year", y = "words"))+
theme(plot.title = element_text(size = 20, face = "bold",hjust = 0.5))
speech.list[which.max(speech.list$great),c("President","Date","great")]
qnorm(0.5)
qnorm(0.9)
ru(10000,0,1)
runif(10000,0,1)
a=rbernoulli(10000,0,1)
a=rbinom(10000,0,1)
sum(a)
rbinom(10000,0,1)
0.5^0.5
.5^.5
.5^.75
a=1/1.06
((a-a^11)/(1-a))*50+a^10＊1000
a=1/1.06
((a-a^11)/(1-a))*50+a^10*1000
a=1/1.03
((a-a^11)/(1-a))*3+a^10*100
a=1/1.04
((a-a^11)/(1-a))*3+a^10*100
2^20
2^19
2^18
2^17
10000*log(10000)
100000*log(100000)
1151293/92103.4
10*log(10)
log(100000)－log(10000)
log(100000)-log(10000)
log(100000)/log(10000)
2^9
2^12
2^13
2^15
2^17
2^16
a=(8/13)*0.03
b=(5/13)*0.04
a^2+b^2
sqrt(a^2+b^2)
0.08^2+0.01
0.0164*0.5*0.5
sqrt(0.0041)
0.15^2+0.09^2*4+2*2*.15*.09
0.1089/9
0.15^2+0.09^2*4+2*2*.15*.09/3
0.0729/9
0.09^2
####################################################
## Project saving and loading
####################################################
shrink <- function(x){
if(is.list(x) && !is.data.frame(x)){
if(is.reactivevalues(x)){
x <- lapply(reactiveValuesToList(x), function(y){
if(typeof(y)!='closure') shrink(y) else NULL
})
attr(x, 'wasReavtive') <- TRUE
} else {
## x is an ordinary list
## need to preserve attributes
attrs <- attributes(x)
x <- lapply(x, shrink)
attributes(x) <- attrs
}
} else {
if(typeof(x)!='closure') x else NULL
}
x
}
wasReactivevalues <- function(x){
!is.null(attr(x, 'wasReavtive'))
}
output$downloadProject <- downloadHandler(
filename = function() { 'MyProject.sData' },
content = function(file) {
isolate({
allData <- list(pp=shrink(projProperties),
dl=lapply(datList, function(d){
list('staticProperties'=d[['staticProperties']],
'dynamicProperties'=shrink(d[['dynamicProperties']]))
}),
sl=lapply(sheetList, function(d){
list('dynamicProperties'=shrink(d[['dynamicProperties']]))
}),
docl=shrink(docList))
save(allData, file=file)
})
}
)
loadProject <- function(file, replaceOrMerge='replace'){
load(file)
if(replaceOrMerge=='replace'){
for(n in names(datList)) datList[[n]] <<- NULL; projProperties[['activeDat']] <<- NULL
for(n in names(sheetList)) sheetList[[n]] <<- NULL; projProperties[['activeSheet']] <<- NULL
for(n in names(docList)) docList[[n]] <<- NULL; projProperties[['activeDoc']] <<- NULL
}
for(n in names(allData$pp)){
if(is.null(projProperties[[n]]) || projProperties[[n]] != allData$pp[[n]]){
projProperties[[n]] <<- allData$pp[[n]]
}
}
for(di in names(allData$dl)){
if(is.null(datList[[di]])){ # new data
datList[[di]] <<- DatClass$new('staticProperties'=allData$dl[[di]][['staticProperties']])
datList[[di]][['dynamicProperties']] <<- reactiveValues()
setDatReactives(di)
}
for(n in names(allData$dl[[di]][['dynamicProperties']])){
x <- allData$dl[[di]][['dynamicProperties']][[n]]
if(n=='fieldsList'){
if(is.null(datList[[di]][['dynamicProperties']][[n]])) datList[[di]][['dynamicProperties']][[n]] <<- list()
names1 <- names(x)
for(n1 in names1){
if(wasReactivevalues(x[[n1]])){
if(is.null(datList[[di]][['dynamicProperties']][[n]][[n1]])) datList[[di]][['dynamicProperties']][[n]][[n1]] <<- reactiveValues()
names2 <- names(x[[n1]])
for(n2 in names2){
datList[[di]][['dynamicProperties']][[n]][[n1]][[n2]] <<- x[[n1]][[n2]]
}
} else {
datList[[di]][['dynamicProperties']][[n]][[n1]] <<- x[[n1]]
}
}
} else {
datList[[di]][['dynamicProperties']][[n]] <<- x
}
}
}
for(si in names(allData$sl)){
if(is.null(sheetList[[si]])){ # new sheet
sheetList[[si]] <<- createNewSheetObj(withPlotLayer=FALSE)
setSheetReactives(si)
}
for(n in names(allData$sl[[si]][['dynamicProperties']])){
x <- allData$sl[[si]][['dynamicProperties']][[n]]
if(n=='layerList'){
if(is.null(sheetList[[si]][['dynamicProperties']][[n]])) sheetList[[si]][['dynamicProperties']][[n]] <<- list()
names1 <- names(x)
for(n1 in names1){
if(wasReactivevalues(x[[n1]])){
if(is.null(sheetList[[si]][['dynamicProperties']][[n]][[n1]]))
sheetList[[si]][['dynamicProperties']][[n]][[n1]] <<- createNewLayer()
names2 <- names(x[[n1]])
for(n2 in names2){
if(n2=='aesList'){
names3 <- names(x[[n1]][[n2]])
for(n3 in names3){
if(wasReactivevalues(x[[n1]][[n2]][[n3]])){
names4 <- names(x[[n1]][[n2]][[n3]])
for(n4 in names4){
sheetList[[si]][['dynamicProperties']][[n]][[n1]][[n2]][[n3]][[n4]] <<- x[[n1]][[n2]][[n3]][[n4]]
}
setAesReactives(si,n1,n3)
} else {
sheetList[[si]][['dynamicProperties']][[n]][[n1]][[n2]][[n3]] <<- x[[n1]][[n2]][[n3]]
}
}
} else {
sheetList[[si]][['dynamicProperties']][[n]][[n1]][[n2]] <<- x[[n1]][[n2]]
}
}
} else {
sheetList[[si]][['dynamicProperties']][[n]][[n1]] <<- x[[n1]]
}
}
} else {
sheetList[[si]][['dynamicProperties']][[n]] <<- x
}
}
}
for(di in names(allData$docl)){
if(is.null(docList[[di]])){ # new doc
docList[[di]] <<- reactiveValues()
}
for(n in names(allData$docl[[di]])){
x <- allData$docl[[di]][[n]]
docList[[di]][[n]] <<- x
}
}
## update all UI
sapply(unique(c(names(input), names(updateInput))), triggerUpdateInput)
updateTabsetPanel(session, 'mainNavBar', selected='Visualize')
}
observe({
inFile <- input[['loadProject']]
isolate({
if (!is.null(inFile)){
loadProject(file=inFile$datapath, replaceOrMerge=input[['loadProjectAction']])
}
})
})
observe({
v <- input$openSampleProj
isolate({
file <- paste('samples', input[['sampleProj']], sep='/')
if(v && file.exists(file)){
loadProject(file=file, 'replace')
}
})
})
spending=read.csv("spending_NYS.csv")
install.packages("maps")
library(maps)
map("state")
map("NY")
map("state")
map("nyc")
library(maps)
map("nyc")
devtools::install_github("zachcp/nycmaps")
libary(nycmaps)
library(maps)
library(maps)
library(nycmaps)
map("nyc")
a=c(1,NA,3,2,NA)
is.na(a)
a[is.na(a)]=0
a
a=c(1,NA,3,2,NA)
a[which(is.na(a))]=0
a
install.packages("shinythemes")
shiny::runApp('Documents/Spr2017-proj2-grp9/shinyapp')
shiny::runApp('Documents/Spr2017-proj2-grp9/shinyapp')
runApp('Documents/Spr2017-proj2-grp9/shinyapp')
a=matrix(NA,nrow=10,ncol=50)
for (j in 1:50)
{ if (j==1)
{a[,j]=rnorm(10)}
else
a[,j]=a[,j-1]+rnorm(10)
}
a
plot(1:50,a[1,])
plot(1:50,a[1,],"l")
for (i in 1:10)
{
line(1:51,c(0,a[i,]),"l",col=i)
}
for (i in 1:10)
{
line(1:51,c(0,a[i,]),col=i)
}
for (i in 1:10)
{
line(1:51,c(0,a[i,]),color=i)
}
for (i in 1:10)
{
line(1:51,c(0,a[i,]))
}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i)}
else
line(1:51,c(0,a[i,]))
}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i)}
else
lines(1:51,c(0,a[i,]))
}
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i)}
else
for (i in 1:10)
{
lines(1:51,c(0,a[i,]),color=i)
}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i)}
else lines(1:51,c(0,a[i,]),color=i)
}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i)}
else lines(1:51,c(0,a[i,]),col=i)
}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i),ylim=c(min(a),max(a))}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i),ylim=c(min(a),max(a))}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i),ylim=c(min(a),max(a)))}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i),ylim=c(min(a),max(a)) )}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i),ylim=c(-20,20))}
for (i in 1:10)
{
if(i==1)
{plot(1:51,c(0,a[i,]),"l",col=i),ylim=(-20,20))}
for (i in 1:10)
{
if(i==1) plot(1:51,c(0,a[i,]),"l",col=i,ylim=c(-20,20))
else lines(1:51,c(0,a[i,]),col=i)
}
for (i in 1:10)
{
if(i==1) plot(1:51,c(0,a[i,]),"l",col=i,ylim=c(min(a)-2,max(a)+2))
else lines(1:51,c(0,a[i,]),col=i)
}
for (i in 1:10)
{
if(i==1) plot(1:51,c(0,a[i,]),"l",col=i,ylim=c(min(a)-2,max(a)+2))
else lines(1:51,c(0,a[i,]),col=i)
}
a=matrix(NA,nrow=10,ncol=50)
for (j in 1:50)
{ if (j==1)
{a[,j]=0}
else
a[,j]=a[,j-1]+rnorm(10)
}
for (i in 1:10)
{
if(i==1) plot(0:50,c(0,a[i,]),"l",col=i,ylim=c(min(a)-2,max(a)+2))
else lines(0:50,c(0,a[i,]),col=i)
}
pbeta(.21,1,13)
pbeta(.21,3,13)
pbeta(.21,13,3)
dbeta(.21,13,3)
dbeta(.21,3,13)
beta(13,3)*(.21^2)*(1-.21)^12
(.21^2)*(1-.21)^12/beta(13,3)
(.21^2)*(1-.21)^12/beta(3,13)
qbinorm()
library(mrvnorm)
library(mvtnorm)
a=c(500*0.01,0.05*500*500);a
b=c(1000*0.005,0.01*10^6);b
cov=matrix(c(12500,0,0,10000),nrow=2);cov
qmvnorm(0.95,sigma=cov,tail="lower.tail")
qmvnorm(0.95,sigma=cov,mean=c(5,5),tail="upper.tail")
cov=matrix(c(0.15,0,0,0.15),nrow=2);cov
diag(2)
qmvnorm(0.95,sigma=cov,mean=c(0.01,0.005),tail="upper.tail")
qmvnorm(0.05,sigma=cov,mean=c(0.01,0.005),tail="upper.tail")
mean=c(0.05,0.05)
sigma=matrix(c(0.15,0,0,0.15),nrow=2)
w=(0.5,0.5)
w=c(0.5,0.5)
t(w)*sigma*w
t(w)%*%sigma%*%w
sigma=matrix(c(0.15^2,0,0,0.15^2),nrow=2)
t(w)*sigma*w
t(w)%*%sigma%*%w
sqrt(0.01125)
a=c(1/3,2/3)
sigma=matrix(c(0.05^2,0.3*0.05*0.01,0.3*0.05*0.01,0.01^2),nrow=2)
t(a)%*%sigma%*%a
0.05^2/9+0.01^
dnorm(1.64)
log6
log(6)
log(6)/log(2)
log(32)/log(2)
dnorm(3.5,mean=3,sd=4)
pnorm(7,mean=3,sd=4)
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
install.packages("gbm")
install.packages("gbm")
library("gbm")
setwd("./ads_spr2017_proj3")
setwd("./spr2017-proj3-grp4")
setwd("../spr2017-proj3-grp4")
setwd("/spr2017-proj3-grp4")
setwd(".../spr2017-proj3-grp4")
getwd()
setwd("~/Documents/spr2017-proj3-grp4")
setwd("~/Documents/spr2017-proj3-grp4")
experiment_dir <- "../data/zipcode/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels = paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep=""),
header=F)
label_train <- as.numeric(unlist(label_train) == "9")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir,
"train",
data_name="zip",
export=TRUE))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(img_test_dir,
"test",
data_name="zip",
export=TRUE))
}
#save(dat_train, file="./output/feature_train.RData")
#save(dat_test, file="./output/feature_test.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file="../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", type="n", ylim=c(0, 0.25))
points(model_values, err_cv[,1], col="blue", pch=16)
lines(model_values, err_cv[,1], col="blue")
arrows(model_values, err_cv[,1]-err_cv[,2], model_values, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
#dev.off()
}
model_best=model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[,1])]
}
par_best <- list(depth=model_best)
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
save(fit_train, file="../output/fit_train.RData")
tm_test=NA
if(run.test){
load(file=paste0("../output/feature_", "zip", "_", "test", ".RData"))
load(file="../output/fit_train.RData")
tm_test <- system.time(pred_test <- test(fit_train, dat_test))
save(pred_test, file="../output/pred_test.RData")
}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")
